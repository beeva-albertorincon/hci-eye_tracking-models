{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 CNN - Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs = utils.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN-TEST\n",
    "train_data, test_data = sklearn.model_selection.train_test_split(data, train_size=0.95, random_state=22)\n",
    "test_imgs_left = np.array([imgs[path] for path in test_data['eye_left_image']])\n",
    "test_imgs_right = np.array([imgs[path] for path in test_data['eye_right_image']])\n",
    "\n",
    "# TRAIN-VALIDATION\n",
    "train_data, validation_data = sklearn.model_selection.train_test_split(data, train_size=0.95, random_state=22)\n",
    "validation_imgs_left = np.array([imgs[path] for path in validation_data['eye_left_image']])\n",
    "validation_imgs_right = np.array([imgs[path] for path in validation_data['eye_right_image']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_placeholders(n_features, img_shape, n_labels):\n",
    "    return(\n",
    "        tf.placeholder(dtype=tf.float32, shape=(None, n_features), name=\"features\"),\n",
    "        tf.placeholder(dtype=tf.float32, shape=(None, *img_shape), name=\"left_imgs\"),\n",
    "        tf.placeholder(dtype=tf.float32, shape=(None, *img_shape), name=\"right_imgs\"),\n",
    "        tf.placeholder(dtype=tf.float32, shape=(None, n_labels), name=\"labels\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(labels, predictions):\n",
    "    '''Average of euclidean distance between labels and predictions\n",
    "    '''\n",
    "    return tf.reduce_mean(\n",
    "        tf.norm(\n",
    "            tf.subtract(labels, predictions),\n",
    "            ord='euclidean',\n",
    "            axis=1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(features, left_imgs, right_imgs, training, dropout_rate=0.7):\n",
    "    new_shape = np.array([-1, 20, 30, 1])\n",
    "    with tf.variable_scope('model'):\n",
    "        # Left Eye Img\n",
    "        l_input = tf.reshape(left_imgs, new_shape)\n",
    "        # 20x30x1\n",
    "        cnn_l_01 = tf.layers.conv2d(\n",
    "            inputs=l_input, \n",
    "            filters=32, \n",
    "            kernel_size=5, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 20x30x32\n",
    "        pool_l_01 = tf.layers.max_pooling2d(\n",
    "            inputs=cnn_l_01,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "        # 10x15x32\n",
    "        cnn_l_02 = tf.layers.conv2d(\n",
    "            inputs=pool_l_01, \n",
    "            filters=128, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )  \n",
    "        # 4x7x128\n",
    "        \n",
    "        # Right Eye Img  \n",
    "        r_input = tf.reshape(right_imgs, new_shape)      \n",
    "        # 20x30x1\n",
    "        cnn_r_01 = tf.layers.conv2d(\n",
    "            inputs=r_input, \n",
    "            filters=32, \n",
    "            kernel_size=5, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 20x30x32\n",
    "        pool_r_01 = tf.layers.max_pooling2d(\n",
    "            inputs=cnn_r_01,\n",
    "            pool_size=[2, 2],\n",
    "            strides=2\n",
    "        )\n",
    "        # 10x15x32 \n",
    "        cnn_r_02 = tf.layers.conv2d(\n",
    "            inputs=pool_r_01, \n",
    "            filters=128, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        # 4x7x128\n",
    "        \n",
    "        # Flatten convs, concat & dense        \n",
    "        left_flat = tf.contrib.layers.flatten (cnn_l_02)\n",
    "        right_flat =  tf.contrib.layers.flatten (cnn_r_02)\n",
    "        img_concat = tf.concat(\n",
    "            values=[left_flat, right_flat],\n",
    "            axis=1\n",
    "        )\n",
    "        img_dense = tf.layers.dense(\n",
    "            inputs=img_concat,\n",
    "            units=128,\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "        img_dropout = tf.layers.dropout(\n",
    "            inputs=img_dense,\n",
    "            rate=dropout_rate,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Concat imgs with features, dense x 2 and output\n",
    "        global_concat = tf.concat(\n",
    "            values=[features, img_dropout],\n",
    "            axis=1\n",
    "        )\n",
    "        global_dense01 = tf.layers.dense(global_concat, 128, activation=tf.nn.relu)\n",
    "        global_dropout01 = tf.layers.dropout(\n",
    "            inputs=global_dense01,\n",
    "            rate=dropout_rate,\n",
    "            training=training\n",
    "        )\n",
    "        global_dense02 = tf.layers.dense(global_dropout01, 64, activation=tf.nn.relu)\n",
    "        global_dropout02 = tf.layers.dropout(\n",
    "            inputs=global_dense02,\n",
    "            rate=dropout_rate,\n",
    "            training=training\n",
    "        )\n",
    "        global_dense03 = tf.layers.dense(global_dropout01, 2, activation=None)\n",
    "        \n",
    "        return global_dense03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = '02-CNN-maxpooling'\n",
    "\n",
    "#\n",
    "### Data parameters\n",
    "#\n",
    "IMG_SHAPE = (20,30)\n",
    "FEATURES = [\n",
    "    'eye_right_x', 'eye_right_y', 'eye_right_width', 'eye_right_height', \n",
    "    'eye_left_x', 'eye_left_y', 'eye_left_width', 'eye_left_height',\n",
    "    'face_x', 'face_y', 'face_width', 'face_height'\n",
    "]\n",
    "TARGETS = ['x','y']\n",
    "\n",
    "#\n",
    "### Hyperparams\n",
    "#\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.005\n",
    "DROPOUT_RATE = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "\n",
    "| Epochs | Batch Size | Learning rate  | Dropout rate | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 10 | 512 | 0.005 | 0.4 | 0.38746994733810425 | 0.40232908725738525 | 0.3758082985877991 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_train = tf.Graph()\n",
    "with tf.Session(graph=graph_train) as sess: \n",
    "    t_features, t_imgs_left, t_imgs_right, t_labels = get_placeholders(len(FEATURES), IMG_SHAPE, len(TARGETS))\n",
    "    model = get_model(t_features, t_imgs_left, t_imgs_right, True, DROPOUT_RATE)\n",
    "    loss = get_loss(t_labels, model)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss=loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    steps = 0 \n",
    "    for epoch in range(EPOCHS):\n",
    "        for b_data, b_imgs_left, b_imgs_right in utils.get_batch(train_data, imgs, BATCH_SIZE):\n",
    "            steps += 1\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                t_features: b_data[FEATURES],\n",
    "                t_imgs_left: b_imgs_left,\n",
    "                t_imgs_right: b_imgs_right,\n",
    "                t_labels: b_data[TARGETS]\n",
    "            })\n",
    "            # Print Info\n",
    "            if steps % 20 == 0:\n",
    "                train_loss = loss.eval({\n",
    "                    t_features: b_data[FEATURES],\n",
    "                    t_imgs_left: b_imgs_left,\n",
    "                    t_imgs_right: b_imgs_right,\n",
    "                    t_labels: b_data[TARGETS]\n",
    "                })\n",
    "                validations_loss = loss.eval({\n",
    "                    t_features: validation_data[FEATURES],\n",
    "                    t_imgs_left: validation_imgs_left,\n",
    "                    t_imgs_right: validation_imgs_right,\n",
    "                    t_labels:validation_data[TARGETS]\n",
    "                    \n",
    "                })\n",
    "                print(\"Epoch: {} of {}\".format(epoch+1, EPOCHS))\n",
    "                print(\"Loss train: {}\".format(train_loss))\n",
    "                print(\"Loss validation: {}\".format(validations_loss))\n",
    "        utils.model_save(sess, MODEL_NAME+\".\"+str(epoch).zfill(4))  # Save after each epoch\n",
    "    utils.model_save(sess, MODEL_NAME+\".final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_test = tf.Graph()\n",
    "with tf.Session(graph=graph_test) as sess:\n",
    "    t_features, t_imgs_left, t_imgs_right, t_labels = get_placeholders(len(FEATURES), IMG_SHAPE, len(TARGETS))\n",
    "    model = get_model(t_features, t_imgs_left, t_imgs_right, training=False, )\n",
    "    loss = get_loss(t_labels, model)\n",
    "    utils.model_load(sess, MODEL_NAME+\".final\")\n",
    "    test_loss = loss.eval({\n",
    "        t_features: test_data[FEATURES],\n",
    "        t_imgs_left: test_imgs_left,\n",
    "        t_imgs_right: test_imgs_right,\n",
    "        t_labels: test_data[TARGETS]\n",
    "    })\n",
    "    print(\"Loss test: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_m = tf.Graph()\n",
    "with tf.Session(graph=graph_m) as sess:\n",
    "    t_features, t_imgs_left, t_imgs_right, t_labels = get_placeholders(len(FEATURES), IMG_SHAPE, len(TARGETS))\n",
    "    model = get_model(t_features, t_imgs_left, t_imgs_right, training=False)\n",
    "    utils.model_load(sess, MODEL_NAME+\".final\")\n",
    "    predictions = sess.run(model, {\n",
    "        t_features: test_data[FEATURES],\n",
    "        t_imgs_left: test_imgs_left,\n",
    "        t_imgs_right: test_imgs_right\n",
    "    })\n",
    "    print(\"PREDICTIONS: {}\".format(predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
