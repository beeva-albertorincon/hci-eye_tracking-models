{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 CNN-Reg-Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from utils import data_model\n",
    "from utils.model import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = data_model.load(\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_CSV,\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_IMGS_LEFT,\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = data_model.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    train_size=0.95,\n",
    "    validation_size=0.95,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/models/06-CRD.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(features, left_imgs, right_imgs, keep_prob):\n",
    "    new_shape = np.array([-1, 20, 30, 1])\n",
    "    with tf.variable_scope('model'):\n",
    "        # Left Eye Img\n",
    "        l_input = tf.reshape(left_imgs, new_shape)\n",
    "        # 20x30x1\n",
    "        cnn_l_01 = tf.layers.conv2d(\n",
    "            inputs=l_input, \n",
    "            filters=32, \n",
    "            kernel_size=3, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        #20x30x32\n",
    "        cnn_l_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_l_01, \n",
    "            filters=64, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        # 10x15x64\n",
    "        \n",
    "        # Right Eye Img  \n",
    "        r_input = tf.reshape(right_imgs, new_shape)      \n",
    "        # 20x30x1\n",
    "        cnn_r_01 = tf.layers.conv2d(\n",
    "            inputs=r_input, \n",
    "            filters=32, \n",
    "            kernel_size=3, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )    \n",
    "        # 20x30x32\n",
    "        cnn_r_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_r_01, \n",
    "            filters=64, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        # 10x15x64\n",
    "        \n",
    "        # Flatten convs, concat & dense        \n",
    "        left_flat = tf.contrib.layers.flatten (cnn_l_02)\n",
    "        right_flat =  tf.contrib.layers.flatten (cnn_r_02)\n",
    "        img_concat = tf.concat(\n",
    "            values=[left_flat, right_flat],\n",
    "            axis=1\n",
    "        )\n",
    "        # 19200\n",
    "        img_dense01 = tf.layers.dense(\n",
    "            inputs=img_concat,\n",
    "            units=4096,\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "        img_dropout01 = tf.nn.dropout(\n",
    "            x=img_dense01,\n",
    "            keep_prob=keep_prob\n",
    "        )        \n",
    "        img_dense02 = tf.layers.dense(\n",
    "            inputs=img_dropout01,\n",
    "            units=1024,\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "        img_dropout02 = tf.nn.dropout(\n",
    "            x=img_dense02,\n",
    "            keep_prob=keep_prob\n",
    "        )       \n",
    "        img_dense03 = tf.layers.dense(\n",
    "            inputs=img_dropout02,\n",
    "            units=512,\n",
    "            activation=tf.nn.relu,\n",
    "        )  \n",
    "        img_dropout03 = tf.nn.dropout(\n",
    "            x=img_dense03,\n",
    "            keep_prob=keep_prob\n",
    "        )       \n",
    "        img_dense04 = tf.layers.dense(\n",
    "            inputs=img_dropout03,\n",
    "            units=256,\n",
    "            activation=tf.nn.relu,\n",
    "        )       \n",
    "        # Concat imgs with features, dense x 2 and output\n",
    "        global_concat = tf.concat(\n",
    "            values=[features, img_dense04],\n",
    "            axis=1\n",
    "        )\n",
    "        global_dense01 = tf.layers.dense(global_concat, 128, activation=tf.nn.relu)\n",
    "        global_dropout01 = tf.nn.dropout(\n",
    "            x=global_dense01,\n",
    "            keep_prob=keep_prob\n",
    "        )\n",
    "        global_dense02 = tf.layers.dense(global_dropout01, 64, activation=tf.nn.relu)\n",
    "        global_dense03 = tf.layers.dense(global_dense02, 2, activation=None)\n",
    "        \n",
    "        return global_dense03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters to adjust: {}\".format(\n",
    "    (\n",
    "        (20*30*32) +\n",
    "        (10*15*64)\n",
    "    )*2 +\n",
    "    (10*15*64*2)*4096 +\n",
    "    (4096*1024) +\n",
    "    (1024*512) + \n",
    "    (512*256) + \n",
    "    (256+12)*128 +\n",
    "    (128*64) +\n",
    "    (64*2)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'CRD-02'\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.0005\n",
    "KEEP_PROB = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME, get_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_data, train_imgs_left, train_imgs_right,\n",
    "    validation_data, validation_imgs_left, validation_imgs_right,\n",
    "    BATCH_SIZE, EPOCHS, LEARNING_RATE, KEEP_PROB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test = Model(MODEL_NAME, saved_model=MODEL_NAME+\".final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test.test(\n",
    "    test_data, test_imgs_left, test_imgs_right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate  | Keep_prob | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| CRD-01 | 10 | 256 | 0.001 | 1.0 | 0.07739225029945374 | 0.1429390162229538 | 0.14581248 |\n",
    "| CRD-02 | 100 | 256 | 0.0005 | 0.85 | 0.05397592484951019 | 0.1266249716281891 | 0.12931317 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
