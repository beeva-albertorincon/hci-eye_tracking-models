{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 CNN-Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from utils import data as utils_data\n",
    "from utils.model import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = utils_data.load(\n",
    "    config.PATH_DATA, config.PATH_IMGS_LEFT, config.PATH_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = utils_data.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    train_size=0.95,\n",
    "    validation_size=0.95,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(features, left_imgs, right_imgs, keep_prob):\n",
    "    new_shape = np.array([-1, 20, 30, 1])\n",
    "    with tf.variable_scope('model'):\n",
    "        # Left Eye Img\n",
    "        l_input = tf.reshape(left_imgs, new_shape)\n",
    "        # 20x30x1\n",
    "        cnn_l_01 = tf.layers.conv2d(\n",
    "            inputs=l_input, \n",
    "            filters=32, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 10x15x32\n",
    "        cnn_l_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_l_01, \n",
    "            filters=64, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        ) \n",
    "        # 4x7x64\n",
    "        \n",
    "        # Right Eye Img  \n",
    "        r_input = tf.reshape(right_imgs, new_shape)      \n",
    "        # 20x30x1\n",
    "        cnn_r_01 = tf.layers.conv2d(\n",
    "            inputs=r_input, \n",
    "            filters=32, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 10x15x32\n",
    "        cnn_r_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_r_01, \n",
    "            filters=64, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        # 4x7x64\n",
    "        \n",
    "        # Flatten convs, concat & dense        \n",
    "        left_flat = tf.contrib.layers.flatten (cnn_l_02)\n",
    "        right_flat =  tf.contrib.layers.flatten (cnn_r_02)\n",
    "        img_concat = tf.concat(\n",
    "            values=[left_flat, right_flat],\n",
    "            axis=1\n",
    "        )\n",
    "        img_dense = tf.layers.dense(\n",
    "            inputs=img_concat,\n",
    "            units=256,\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "        \n",
    "        # Concat imgs with features, dense x 2 and output\n",
    "        global_concat = tf.concat(\n",
    "            values=[features, img_dense],\n",
    "            axis=1\n",
    "        )\n",
    "        global_dense01 = tf.layers.dense(global_concat, 128, activation=tf.nn.relu)\n",
    "        global_dropout01 = tf.nn.dropout(\n",
    "            x=global_dense01,\n",
    "            keep_prob=keep_prob\n",
    "        )\n",
    "        global_dense02 = tf.layers.dense(global_dropout01, 64, activation=tf.nn.relu)\n",
    "        global_dense03 = tf.layers.dense(global_dense02, 2, activation=None)\n",
    "        \n",
    "        return global_dense03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'cnn_simple-06'\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.0002\n",
    "KEEP_PROB = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME, get_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_data, train_imgs_left, train_imgs_right,\n",
    "    validation_data, validation_imgs_left, validation_imgs_right,\n",
    "    BATCH_SIZE, EPOCHS, LEARNING_RATE, KEEP_PROB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test = Model(MODEL_NAME, saved_model=MODEL_NAME+\".final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test.test(\n",
    "    test_data, test_imgs_left, test_imgs_right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate  | Keep_prob | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| cnn_simple-01 | 10 | 256 | 0.003 | 1.0 | 0.13434778153896332 | 0.19420433044433594 | 0.19306178 |\n",
    "| cnn_simple-02 | 40 | 256 | 0.0005 | 0.9 | 0.06496571749448776 | 0.16198869049549103 | 0.15953958 |\n",
    "| cnn_simple-03 | 40 | 256 | 0.0001 | 0.8 | 0.10085277259349823 | 0.17251187562942505 | 0.16782267 |\n",
    "| cnn_simple-04 | 50 | 256 | 0.0003 | 0.85 | 0.06626483052968979 | 0.16012543439865112 | 0.16782267 |\n",
    "| cnn_simple-05 | 100 | 256 | 0.001 | 0.50 | 0.09738671779632568 | 0.19700293242931366 | 0.1929463 |\n",
    "| cnn_simple-06 | 50 | 256 | 0.0001 | 0.7 | 0.09397947788238525 | 0.17506185173988342 | 0.17135754 |\n",
    "| cnn_simple-07 | 100 | 256 | 0.0001 | 0.7 | 0.07396189123392105 | 0.16842615604400635 | 0.16878742 |\n",
    "| cnn_simple-08 | 100 | 512 | 0.0001 | 0.9 | 0.07066092640161514 | 0.16528385877609253 | 0.16040522 |\n",
    "| cnn_simple-09 | 100 | 512 | 0.0002 | 0.85 | 0.058131735771894455 | 0.16360823810100555 | 0.16219755 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
