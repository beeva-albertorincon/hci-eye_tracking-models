{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import utils_data\n",
    "from utils_model import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = utils_data.load(\n",
    "    config.PATH_DATA, config.PATH_IMGS_LEFT, config.PATH_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = utils_data.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    train_size=0.95,\n",
    "    validation_size=0.95,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(features, left_imgs, right_imgs, keep_prob):\n",
    "    new_shape = np.array([-1, 20, 30, 1])\n",
    "    with tf.variable_scope('model'):\n",
    "        # Left Eye Img\n",
    "        l_input = tf.reshape(left_imgs, new_shape)\n",
    "        # 20x30x1\n",
    "        cnn_l_01 = tf.layers.conv2d(\n",
    "            inputs=l_input, \n",
    "            filters=32, \n",
    "            kernel_size=5, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 20x30x32\n",
    "        cnn_l_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_l_01, \n",
    "            filters=64, \n",
    "            kernel_size=5, \n",
    "            strides=2,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 10x15x64\n",
    "        cnn_l_03 = tf.layers.conv2d(\n",
    "            inputs=cnn_l_02, \n",
    "            filters=128, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        ) \n",
    "        # 4x7x128\n",
    "        \n",
    "        # Right Eye Img  \n",
    "        r_input = tf.reshape(right_imgs, new_shape)      \n",
    "        # 20x30x1\n",
    "        cnn_r_01 = tf.layers.conv2d(\n",
    "            inputs=r_input, \n",
    "            filters=32, \n",
    "            kernel_size=5, \n",
    "            strides=1,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 20x30x32\n",
    "        cnn_r_02 = tf.layers.conv2d(\n",
    "            inputs=cnn_r_01, \n",
    "            filters=64, \n",
    "            kernel_size=5, \n",
    "            strides=2,\n",
    "            padding=\"SAME\"\n",
    "        )\n",
    "        # 10x15x64\n",
    "        cnn_r_03 = tf.layers.conv2d(\n",
    "            inputs=cnn_r_02, \n",
    "            filters=128, \n",
    "            kernel_size=3, \n",
    "            strides=2,\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        # 4x7x128\n",
    "        \n",
    "        # Flatten convs, concat & dense        \n",
    "        left_flat = tf.contrib.layers.flatten (cnn_l_03)\n",
    "        right_flat =  tf.contrib.layers.flatten (cnn_r_03)\n",
    "        img_concat = tf.concat(\n",
    "            values=[left_flat, right_flat],\n",
    "            axis=1\n",
    "        )\n",
    "        img_dense = tf.layers.dense(\n",
    "            inputs=img_concat,\n",
    "            units=128,\n",
    "            activation=tf.nn.relu,\n",
    "        )\n",
    "        img_dropout = tf.nn.dropout(\n",
    "            x=img_dense,\n",
    "            keep_prob=keep_prob\n",
    "        )\n",
    "        \n",
    "        # Concat imgs with features, dense x 2 and output\n",
    "        global_concat = tf.concat(\n",
    "            values=[features, img_dropout],\n",
    "            axis=1\n",
    "        )\n",
    "        global_dense01 = tf.layers.dense(global_concat, 128, activation=tf.nn.relu)\n",
    "        global_dropout01 = tf.nn.dropout(\n",
    "            x=global_dense01,\n",
    "            keep_prob=keep_prob\n",
    "        )\n",
    "        global_dense02 = tf.layers.dense(global_dropout01, 64, activation=tf.nn.relu)\n",
    "        global_dropout02 = tf.nn.dropout(\n",
    "            x=global_dense02,\n",
    "            keep_prob=keep_prob\n",
    "        )\n",
    "        global_dense03 = tf.layers.dense(global_dropout01, 2, activation=None)\n",
    "        \n",
    "        return global_dense03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'CNN 01'\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.005\n",
    "KEEP_PROB = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME, get_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_data, train_imgs_left, train_imgs_right,\n",
    "    validation_data, validation_imgs_left, validation_imgs_right,\n",
    "    BATCH_SIZE, EPOCHS, LEARNING_RATE, KEEP_PROB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test = Model(MODEL_NAME, get_model, saved_model=MODEL_NAME+\".final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test.test(\n",
    "    test_data, test_imgs_left, test_imgs_right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate  | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|  | 10 | 512 | 0.005 | 0.17767135798931122 | 0.2149958461523056 | 0.3488619327545166 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
